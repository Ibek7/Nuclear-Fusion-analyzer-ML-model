{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8212d65f",
   "metadata": {},
   "source": [
    "# Nuclear Fusion Data - Exploratory Data Analysis\n",
    "\n",
    "This notebook performs comprehensive exploratory data analysis on nuclear fusion plasma data.\n",
    "\n",
    "## Contents\n",
    "1. Data Loading and Overview\n",
    "2. Statistical Analysis\n",
    "3. Plasma Parameter Visualization\n",
    "4. Correlation Analysis\n",
    "5. Feature Engineering\n",
    "6. Anomaly Detection\n",
    "7. Performance Metrics Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46eed4e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import sys\n",
    "import os\n",
    "sys.path.append('..')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# Import fusion analyzer modules\n",
    "from src.data.generator import FusionDataGenerator\n",
    "from src.data.processor import FusionDataProcessor\n",
    "from src.visualization.plotter import FusionPlotter\n",
    "from src.models.anomaly_detector import FusionAnomalyDetector\n",
    "\n",
    "# Set style\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b39f5b2d",
   "metadata": {},
   "source": [
    "## 1. Data Loading and Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "975d6394",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate synthetic fusion data\n",
    "generator = FusionDataGenerator()\n",
    "data = generator.generate_dataset(n_samples=5000)\n",
    "\n",
    "print(f\"Dataset shape: {data.shape}\")\n",
    "print(f\"\\nColumns: {list(data.columns)}\")\n",
    "print(f\"\\nData types:\")\n",
    "print(data.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c5f2030",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic statistics\n",
    "print(\"Dataset Overview:\")\n",
    "print(f\"Number of samples: {len(data)}\")\n",
    "print(f\"Number of features: {len(data.columns)}\")\n",
    "print(f\"Memory usage: {data.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
    "\n",
    "# Missing values\n",
    "missing_values = data.isnull().sum()\n",
    "if missing_values.sum() > 0:\n",
    "    print(f\"\\nMissing values:\")\n",
    "    print(missing_values[missing_values > 0])\n",
    "else:\n",
    "    print(\"\\nNo missing values found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3c72dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display first few rows\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "679f4f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical summary\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "896f8923",
   "metadata": {},
   "source": [
    "## 2. Plasma Parameter Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d9380e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze key plasma parameters\n",
    "plasma_params = ['plasma_temperature', 'plasma_density', 'magnetic_field', \n",
    "                'pressure', 'confinement_time', 'beta_plasma', 'safety_factor']\n",
    "\n",
    "# Create subplot for plasma parameters\n",
    "fig, axes = plt.subplots(3, 3, figsize=(15, 12))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, param in enumerate(plasma_params):\n",
    "    if param in data.columns:\n",
    "        axes[i].hist(data[param], bins=50, alpha=0.7, edgecolor='black')\n",
    "        axes[i].set_title(f'{param.replace(\"_\", \" \").title()}')\n",
    "        axes[i].grid(True, alpha=0.3)\n",
    "        \n",
    "        # Add statistics\n",
    "        mean_val = data[param].mean()\n",
    "        std_val = data[param].std()\n",
    "        axes[i].axvline(mean_val, color='red', linestyle='--', \n",
    "                       label=f'Mean: {mean_val:.2e}')\n",
    "        axes[i].legend()\n",
    "\n",
    "# Remove empty subplots\n",
    "for i in range(len(plasma_params), len(axes)):\n",
    "    fig.delaxes(axes[i])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.suptitle('Plasma Parameter Distributions', fontsize=16, y=1.02)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cfe7da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q factor analysis\n",
    "if 'q_factor' in data.columns:\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "    \n",
    "    # Q factor distribution\n",
    "    axes[0].hist(data['q_factor'], bins=50, alpha=0.7, edgecolor='black')\n",
    "    axes[0].axvline(1.0, color='red', linestyle='--', label='Breakeven (Q=1)')\n",
    "    axes[0].axvline(5.0, color='orange', linestyle='--', label='Ignition (Q=5)')\n",
    "    axes[0].set_xlabel('Q Factor')\n",
    "    axes[0].set_ylabel('Frequency')\n",
    "    axes[0].set_title('Q Factor Distribution')\n",
    "    axes[0].legend()\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Q factor vs time\n",
    "    axes[1].plot(data.index, data['q_factor'], alpha=0.6)\n",
    "    axes[1].axhline(1.0, color='red', linestyle='--', label='Breakeven')\n",
    "    axes[1].set_xlabel('Sample Index')\n",
    "    axes[1].set_ylabel('Q Factor')\n",
    "    axes[1].set_title('Q Factor Over Time')\n",
    "    axes[1].legend()\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Performance categories\n",
    "    q_categories = pd.cut(data['q_factor'], \n",
    "                         bins=[0, 0.1, 1.0, 5.0, np.inf],\n",
    "                         labels=['Very Low', 'Sub-critical', 'Breakeven+', 'Ignition+'])\n",
    "    \n",
    "    q_counts = q_categories.value_counts()\n",
    "    axes[2].pie(q_counts.values, labels=q_counts.index, autopct='%1.1f%%')\n",
    "    axes[2].set_title('Performance Categories')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print Q factor statistics\n",
    "    print(f\"Q Factor Statistics:\")\n",
    "    print(f\"Mean: {data['q_factor'].mean():.3f}\")\n",
    "    print(f\"Median: {data['q_factor'].median():.3f}\")\n",
    "    print(f\"Max: {data['q_factor'].max():.3f}\")\n",
    "    print(f\"Breakeven rate (Q >= 1): {(data['q_factor'] >= 1.0).mean()*100:.1f}%\")\n",
    "    print(f\"Ignition rate (Q >= 5): {(data['q_factor'] >= 5.0).mean()*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79658ef9",
   "metadata": {},
   "source": [
    "## 3. Correlation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "972df4e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate correlation matrix for numerical columns\n",
    "numerical_cols = data.select_dtypes(include=[np.number]).columns\n",
    "correlation_matrix = data[numerical_cols].corr()\n",
    "\n",
    "# Create correlation heatmap\n",
    "plt.figure(figsize=(14, 12))\n",
    "mask = np.triu(np.ones_like(correlation_matrix, dtype=bool))\n",
    "sns.heatmap(correlation_matrix, mask=mask, annot=True, cmap='RdBu_r', \n",
    "            center=0, square=True, cbar_kws={\"shrink\": .8})\n",
    "plt.title('Parameter Correlation Matrix')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a058fb51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find strong correlations with Q factor\n",
    "if 'q_factor' in data.columns:\n",
    "    q_correlations = correlation_matrix['q_factor'].abs().sort_values(ascending=False)\n",
    "    \n",
    "    print(\"Strongest correlations with Q Factor:\")\n",
    "    print(q_correlations[1:11])  # Top 10 (excluding self-correlation)\n",
    "    \n",
    "    # Visualize top correlations\n",
    "    top_corr_features = q_correlations[1:6].index  # Top 5\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    for i, feature in enumerate(top_corr_features):\n",
    "        axes[i].scatter(data[feature], data['q_factor'], alpha=0.5)\n",
    "        axes[i].set_xlabel(feature.replace('_', ' ').title())\n",
    "        axes[i].set_ylabel('Q Factor')\n",
    "        \n",
    "        # Add correlation coefficient\n",
    "        corr_coef = correlation_matrix.loc['q_factor', feature]\n",
    "        axes[i].set_title(f'Correlation: {corr_coef:.3f}')\n",
    "        axes[i].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Remove empty subplot\n",
    "    fig.delaxes(axes[5])\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.suptitle('Q Factor vs Key Parameters', fontsize=16, y=1.02)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdd59a69",
   "metadata": {},
   "source": [
    "## 4. Feature Engineering Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ef6703f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply feature engineering\n",
    "processor = FusionDataProcessor()\n",
    "engineered_data = processor.engineer_features(data)\n",
    "\n",
    "print(f\"Original features: {len(data.columns)}\")\n",
    "print(f\"Engineered features: {len(engineered_data.columns)}\")\n",
    "print(f\"New features added: {len(engineered_data.columns) - len(data.columns)}\")\n",
    "\n",
    "# List new features\n",
    "new_features = set(engineered_data.columns) - set(data.columns)\n",
    "print(f\"\\nNew engineered features:\")\n",
    "for feature in sorted(new_features):\n",
    "    print(f\"  - {feature}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e280fb20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze some key engineered features\n",
    "key_engineered = ['thermal_energy_density', 'magnetic_pressure', 'power_efficiency', \n",
    "                 'normalized_lawson', 'troyon_beta_ratio']\n",
    "\n",
    "available_engineered = [f for f in key_engineered if f in engineered_data.columns]\n",
    "\n",
    "if available_engineered:\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    for i, feature in enumerate(available_engineered):\n",
    "        if i < len(axes):\n",
    "            axes[i].hist(engineered_data[feature], bins=50, alpha=0.7, edgecolor='black')\n",
    "            axes[i].set_title(feature.replace('_', ' ').title())\n",
    "            axes[i].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Remove empty subplots\n",
    "    for i in range(len(available_engineered), len(axes)):\n",
    "        fig.delaxes(axes[i])\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.suptitle('Engineered Feature Distributions', fontsize=16, y=1.02)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e76000dd",
   "metadata": {},
   "source": [
    "## 5. Anomaly Detection Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05184693",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate some anomalous data\n",
    "anomaly_data = generator.generate_anomaly_data(data, anomaly_fraction=0.05)\n",
    "\n",
    "print(f\"Total samples: {len(anomaly_data)}\")\n",
    "print(f\"Anomalous samples: {anomaly_data['is_anomaly'].sum()}\")\n",
    "print(f\"Anomaly rate: {anomaly_data['is_anomaly'].mean()*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e726de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze anomaly characteristics\n",
    "normal_data = anomaly_data[~anomaly_data['is_anomaly']]\n",
    "anomalous_data = anomaly_data[anomaly_data['is_anomaly']]\n",
    "\n",
    "# Compare key parameters between normal and anomalous samples\n",
    "comparison_params = ['plasma_temperature', 'q_factor', 'plasma_stability', 'disruption_probability']\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, param in enumerate(comparison_params):\n",
    "    if param in anomaly_data.columns:\n",
    "        axes[i].hist(normal_data[param], bins=30, alpha=0.7, \n",
    "                    label='Normal', color='blue', density=True)\n",
    "        axes[i].hist(anomalous_data[param], bins=30, alpha=0.7, \n",
    "                    label='Anomalous', color='red', density=True)\n",
    "        axes[i].set_xlabel(param.replace('_', ' ').title())\n",
    "        axes[i].set_ylabel('Density')\n",
    "        axes[i].legend()\n",
    "        axes[i].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.suptitle('Normal vs Anomalous Sample Comparison', fontsize=16, y=1.02)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff826a1d",
   "metadata": {},
   "source": [
    "## 6. Performance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb0f193",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze fusion performance metrics\n",
    "performance_metrics = ['q_factor', 'fusion_power', 'lawson_criterion', \n",
    "                      'triple_product', 'energy_confinement_time']\n",
    "\n",
    "available_metrics = [m for m in performance_metrics if m in data.columns]\n",
    "\n",
    "if len(available_metrics) >= 2:\n",
    "    # Create performance correlation matrix\n",
    "    perf_corr = data[available_metrics].corr()\n",
    "    \n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(perf_corr, annot=True, cmap='RdBu_r', center=0, \n",
    "                square=True, cbar_kws={\"shrink\": .8})\n",
    "    plt.title('Performance Metrics Correlation')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baca370d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance vs operational mode\n",
    "if 'operational_mode' in data.columns and 'q_factor' in data.columns:\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    # Box plot of Q factor by operational mode\n",
    "    sns.boxplot(data=data, x='operational_mode', y='q_factor')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.title('Q Factor Distribution by Operational Mode')\n",
    "    plt.axhline(y=1.0, color='red', linestyle='--', alpha=0.7, label='Breakeven')\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Summary statistics by mode\n",
    "    mode_stats = data.groupby('operational_mode')['q_factor'].agg(['mean', 'median', 'std', 'count'])\n",
    "    print(\"\\nQ Factor Statistics by Operational Mode:\")\n",
    "    print(mode_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5427b4e",
   "metadata": {},
   "source": [
    "## 7. Summary and Insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c78691f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate summary insights\n",
    "print(\"FUSION DATA ANALYSIS SUMMARY\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Dataset overview\n",
    "print(f\"Dataset Size: {len(data):,} samples, {len(data.columns)} features\")\n",
    "print(f\"Data Quality: {(1 - data.isnull().sum().sum() / data.size) * 100:.1f}% complete\")\n",
    "\n",
    "# Performance insights\n",
    "if 'q_factor' in data.columns:\n",
    "    breakeven_rate = (data['q_factor'] >= 1.0).mean() * 100\n",
    "    ignition_rate = (data['q_factor'] >= 5.0).mean() * 100\n",
    "    print(f\"\\nPerformance Metrics:\")\n",
    "    print(f\"  - Breakeven Achievement Rate: {breakeven_rate:.1f}%\")\n",
    "    print(f\"  - Ignition Achievement Rate: {ignition_rate:.1f}%\")\n",
    "    print(f\"  - Average Q Factor: {data['q_factor'].mean():.3f}\")\n",
    "\n",
    "# Anomaly insights\n",
    "if 'is_anomaly' in anomaly_data.columns:\n",
    "    anomaly_rate = anomaly_data['is_anomaly'].mean() * 100\n",
    "    print(f\"\\nAnomaly Analysis:\")\n",
    "    print(f\"  - Anomaly Rate: {anomaly_rate:.2f}%\")\n",
    "    \n",
    "    if 'disruption_probability' in anomaly_data.columns:\n",
    "        avg_disruption_risk = anomaly_data['disruption_probability'].mean() * 100\n",
    "        print(f\"  - Average Disruption Risk: {avg_disruption_risk:.1f}%\")\n",
    "\n",
    "# Feature insights\n",
    "print(f\"\\nFeature Engineering:\")\n",
    "print(f\"  - Original Features: {len(data.columns)}\")\n",
    "print(f\"  - Engineered Features: {len(engineered_data.columns)}\")\n",
    "print(f\"  - Feature Expansion: {(len(engineered_data.columns) / len(data.columns) - 1) * 100:.1f}%\")\n",
    "\n",
    "# Correlation insights\n",
    "if 'q_factor' in correlation_matrix.columns:\n",
    "    top_corr = correlation_matrix['q_factor'].abs().nlargest(6)\n",
    "    print(f\"\\nStrongest Q Factor Correlations:\")\n",
    "    for feature, corr in top_corr[1:4].items():  # Top 3 (excluding self)\n",
    "        print(f\"  - {feature}: {corr:.3f}\")\n",
    "\n",
    "print(\"\\nAnalysis Complete!\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
